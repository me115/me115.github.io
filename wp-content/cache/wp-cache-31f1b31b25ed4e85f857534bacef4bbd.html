<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>大CC</title>
	<atom:link href="http://blog.me115.com/feed" rel="self" type="application/rss+xml" />
	<link>http://blog.me115.com</link>
	<description>关注 Nosql/架构/时间管理/阅读分享</description>
	<lastBuildDate>Wed, 25 May 2016 13:08:34 +0000</lastBuildDate>
	<language>zh-CN</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.org/?v=3.5</generator>
		<item>
		<title>godep 包管理工具</title>
		<link>http://blog.me115.com/2016/05/935</link>
		<comments>http://blog.me115.com/2016/05/935#comments</comments>
		<pubDate>Wed, 25 May 2016 13:08:34 +0000</pubDate>
		<dc:creator>大CC</dc:creator>
				<category><![CDATA[GO语言]]></category>

		<guid isPermaLink="false">http://blog.me115.com/?p=935</guid>
		<description><![CDATA[godep是解决包依赖的管理工具 安装 go get github.com/to &#8230;<p class="read-more"><a href="http://blog.me115.com/2016/05/935">继续阅读 &#187;</a></p>]]></description>
				<content:encoded><![CDATA[<p>godep是解决包依赖的管理工具</p>

<h2>安装</h2>

<pre><code>go get github.com/tools/godep
</code></pre>

<p>成功安装后，在GOPATH的bin目录下会有一个godep可执行的二进制文件，后面执行的命令都是用这个，间隔这个目录加入到PATH目录中。</p>

<h2>编译和运行</h2>

<p>项目用godep管理后，要编译和运行项目的时候再用go run和go build显然就不行了，因为go命令是直接到GOPATH目录下去找第三方库。而使用godep下载的依赖库放到Godeps/workspace目录下的；</p>

<pre><code>godep go build XXX
</code></pre>

<p>godep中的go命令，就是将原先的go命令加了一层壳，执行godep go的时候，会将当前项目的workspace目录加入GOPATH变量中；</p>

<h2>godep save</h2>

<p>godep save将项目中使用到的第三方库复制到项目的Godeps目录下。</p>

<p>godep save 会自动扫描当前目录所属包中import的所有外部依赖库（非系统库），并查看其是否属于某个代码管理工具（比如git，hg）。若是，则把此库获取路径和当前对应的revision（commit id）记录到当前目录Godeps下的Godeps.json，同时，把不含代码管理信息（如.git目录）的代码拷贝到Godeps/_workspace/src下，用于后继godep go build等命令执行时固定查找依赖包的路径。</p>

<p>因此，godep save能否成功执行需要有两个要素：当前或者需扫描的包均能够编译成功：因此所有依赖包事先都应该已经或go get或手工操作保存到当前GOPATH路径下依赖包必须使用了某个代码管理工具（如git，hg）：这是因为godep需要记录revision</p>

<h2>godep restore</h2>

<p>如果下载的项目中只有Godeps.json文件，而没有包含第三库则可以使用godep restore这个命令将所有的依赖库下来下来到GOPATH的src中。</p>

<pre><code>godep restore
</code></pre>

<p>godep restore执行时，godep会按照Godeps/Godeps.json内列表，依次执行go get -d -v 来下载对应依赖包到GOPATH路径下，因此，如果某个原先的依赖包保存路径（GOPATH下的相对路径）与下载url路径不一致，比如kuberbetes在github上路径是github.com/kubernetes，而代码内import则是k8s.io，则会导致无法下载成功，也就是说godep restore不成功。这种只能手动，比如手动创建$GOPATH/k8s.io目录，然后git clone。</p>

<h2>golang自带包管理工具</h2>

<p>自带工具：go get go get可以将依赖的第三方库下载本GOPATH目录，在代码中直接import相应的代码库就可以了。与godep相比，如果项目引用的第三方库没有列入到项目里面，安装项目时，针对第三方库需要使用go get一个个下载，比较麻烦；</p>

<p>注：使用godep restore可能导致部分库无法下载下来；编译会报错： cmd/decode.go:16:2: cannot find package &quot;github.com/CodisLabs/redis-port/pkg/libs/atomic2&quot; in any of:</p>

<p>此时针对报错的特定库再go get一般都能下载： go get github.com/CodisLabs/redis-port/pkg/libs/atomic2</p>

<h2>godep支持的命令</h2>

<pre><code>save     list and copy dependencies into Godeps
go       run the go tool with saved dependencies
get      download and install packages with specified dependencies
path     print GOPATH for dependency code
restore  check out listed dependency versions in GOPATH
update   update selected packages or the go version
diff     shows the diff between current and previously saved set of dependencies
version  show version info
</code></pre>

<div class="ujian-hook"></div><div style='clear:both;'></div>

 
		<script type="text/javascript">
		var ujian_config = {
			'num':5,
			'showType':2,
			'bgColor':"",
			'mouseoverColor':"#E6F3DE",
			'textColor':"#333333",
			'hoverTextColor':"#333333",
			'borderColor':"#dddddd",
			'picSize':96,
			'target':1,
			'textHeight':60,
			'defaultPic':"",
			'itemTitle':"您可能喜欢："
		}</script>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>]]></content:encoded>
			<wfw:commentRss>http://blog.me115.com/2016/05/935/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>git常用命令</title>
		<link>http://blog.me115.com/2016/05/933</link>
		<comments>http://blog.me115.com/2016/05/933#comments</comments>
		<pubDate>Wed, 25 May 2016 13:07:56 +0000</pubDate>
		<dc:creator>大CC</dc:creator>
				<category><![CDATA[未分类]]></category>

		<guid isPermaLink="false">http://blog.me115.com/?p=933</guid>
		<description><![CDATA[git常用命令 初始化仓库 新建仓库 对现有的项目进行管理，进入该项目目录并输入 &#8230;<p class="read-more"><a href="http://blog.me115.com/2016/05/933">继续阅读 &#187;</a></p>]]></description>
				<content:encoded><![CDATA[<h1>git常用命令</h1>

<h2>初始化仓库</h2>

<ul>   <li>     <p>新建仓库 对现有的项目进行管理，进入该项目目录并输入</p>      <pre><code>git init
</code></pre>
  </li>
</ul>

<p>ps:该命令将创建.git目录，但不会主动将现有项目中的文件纳入管理（需要自行添加）；</p>

<ul>
  <li>
    <p>克隆仓库</p>

    <pre><code>git clone https://github.com/libgit2/libgit2 
</code></pre>
  </li>
</ul>

<h2>文件的四种状态</h2>

<ol>
  <li>
    <p>未跟踪 untracked 
      <br />通过以下操作到达未跟踪状态：</p>

    <pre><code>新建文件 vi aaa
从索引区删除文件  git rm
</code></pre>
  </li>

  <li>
    <p>未修改 unmodified 以下操作到达未修改状态：</p>

    <pre><code>git commit
</code></pre>
  </li>

  <li>
    <p>已修改 modified 
      <br />到达已修改状态：</p>

    <pre><code> vi aaa
</code></pre>
  </li>

  <li>
    <p>已暂存 staged</p>

    <pre><code>添加 git add
</code></pre>
  </li>
</ol>

<h3>查看当前状态</h3>

<ul>
  <li>
    <p>当前状态 </p>

    <pre><code>git status
</code></pre>
  </li>

  <li>
    <p>状态简览 </p>

    <pre><code>git status -s
</code></pre>
  </li>
</ul>

<p>PS: ‘MM’ 标记：左边M：修改并放入暂存区； 右边M：修改了还未放入暂存区</p>

<ul>
  <li>
    <p>查看尚未暂存的差异</p>

    <pre><code>git diff 
</code></pre>
  </li>

  <li>
    <p>查看已暂存的将要添加到下次提交里的内容</p>

    <pre><code>git diff --staged
</code></pre>
  </li>
</ul>

<h2>三个工作区域</h2>

<ul>
  <li>Git仓库 </li>

  <li>工作目录 </li>

  <li>暂存区域 </li>
</ul>

<p>基本的 Git 工作流程</p>

<ol>
  <li>
    <p>在工作目录中修改文件。</p>

    <pre><code>vi aaa
</code></pre>
  </li>

  <li>
    <p>暂存文件，将文件的快照放入暂存区域。</p>

    <pre><code>git add .
</code></pre>
  </li>

  <li>
    <p>提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。</p>

    <pre><code>git commit -m &quot;add file&quot; aaa 
</code></pre>

    <p>已跟踪的文件修改，直接提交到库中：</p>

    <pre><code>git commit -a -m &quot;update file aaa&quot; aaa
</code></pre>
  </li>
</ol>

<h2>移除文件</h2>

<ul>
  <li>
    <p>从暂存区中移除文件（硬盘上也删除）</p>

    <pre><code>  git rm 
</code></pre>
  </li>

  <li>
    <p>从暂存区中移除文件（硬盘上保留，即不再跟踪此文件）</p>

    <pre><code>  git rm --cached README 
</code></pre>
  </li>

  <li>
    <p>移动文件</p>

    <pre><code>  git mv a b 
</code></pre>
  </li>
</ul>

<h2>暂存区的操作</h2>

<ul>
  <li>
    <p>提交暂存</p>

    <pre><code>  git commit -m &quot;update what&quot; 
</code></pre>
  </li>

  <li>
    <p>补充提交</p>

    <pre><code>  git commit --amend 
</code></pre>

    <p>最终只会显示成一个提交</p>
  </li>

  <li>
    <p>取消暂存</p>

    <pre><code>  git reset HEAD readme
</code></pre>

    <p>将readme文件从暂存状态更改为未跟踪状态</p>
  </li>

  <li>
    <p>回退到指定版本</p>

    <pre><code>  git reset --hard :commit_hash_id
</code></pre>
  </li>
</ul>

<h2>查看提交历史</h2>

<ul>
  <li>
    <p>查看日志</p>

    <pre><code>  git log
</code></pre>
  </li>

  <li>
    <p>显示最近两次提交的内容差异</p>

    <pre><code>  git log -p -2 
</code></pre>
  </li>

  <li>
    <p>单行显示</p>

    <pre><code>$git log --pretty=oneline  
$git log --oneline --decorate
$git log --pretty=format:&quot;%h - %an, %ar : %s&quot;
  8029c4c - colin, 10 days ago : add redis_gallery_ad_impr
</code></pre>
  </li>

  <li>
    <p>仅查看指定提交者的提交记录</p>

    <pre><code>$ git log --committer=colin
</code></pre>
  </li>
</ul>

<h2>远程仓库操作</h2>

<ul>
  <li>
    <p>查看远程仓库</p>

    <pre><code>git remote -v 
</code></pre>
  </li>

  <li>
    <p>更新本地远程仓库数据拉取（不自动合并到当前工作目录）：</p>

    <pre><code>git fetch origin 
git merge origin/serverfix 将origin/serverfix合并到当前的分支
</code></pre>
  </li>

  <li>
    <p>远程数据拉取并合并到当前目录：</p>

    <pre><code>git pull origin
</code></pre>

    <p>自动到远程origin的跟踪分支上拉取并合并数据</p>
  </li>

  <li>
    <p>推送到远程仓库</p>

    <pre><code>git push origin master
git push origin serverfix:serverfix 
</code></pre>

    <p>推送本地的 serverfix 分支，将其作为远程仓库的 serverfix 分支</p>
  </li>
</ul>

<h2>分支操作</h2>

<h3>创建分支</h3>

<pre><code>git branch testing
</code></pre>

<h3>分支切换</h3>

<p>切换到已存在的分支上(HEAD 就指向这个分支)</p>

<pre><code>  git checkout testing
</code></pre>

<h3>新建并切换</h3>

<p>基于当前目录新建一个分支并切换工作区到新分支上：</p>

<pre><code>  git checkout -b iss53
</code></pre>

<p>新建一个基于远程仓库origin上的serverfix的分支：</p>

<pre><code>  git fetch origin
  git checkout -b serverfix origin/serverfix
  or：
  git checkout --track origin/serverfix
</code></pre>

<h3>跟踪分支</h3>

<ul>
  <li>
    <p>设置跟踪设置已有的本地分支跟踪一个刚刚拉取下来的远程分支，或者想要修改正在跟踪的上游分支：</p>

    <pre><code>git branch -u origin/serverfix
</code></pre>
  </li>

  <li>
    <p>查询跟踪关系查看设置的所有跟踪分支</p>

    <pre><code>git branch -vv
</code></pre>
  </li>
</ul>

<h3>删除分支</h3>

<ul>
  <li>
    <p>删除本地分支</p>

    <pre><code>git branch -d hotfix
</code></pre>
  </li>

  <li>
    <p>删除远程分支</p>

    <pre><code>git push origin --delete serverfix
</code></pre>
  </li>
</ul>

<h3>分支合并</h3>

<ul>
  <li>
    <p>合并merge 合并 iss53 分支到master 分支(ps：被合并的分支为当前工作区)</p>

    <pre><code>git checkout master
git merge iss53
</code></pre>
  </li>

  <li>
    <p>变基rebase 变基是将一系列提交按照原有次序依次应用到另一分支上，而合并是把最终结果合在一起。</p>

    <pre><code>git checkout experiment
git rebase master
</code></pre>
  </li>
</ul>

<h3>查看当前分支列表</h3>

<pre><code>git branch
</code></pre>

<p>ref：《Pro Git 2.0》</p>

<p>Posted by: 大CC | 14MAY,2016 博客：<a href="http://blog.me115.com">blog.me115.com</a> [<a href="http://blog.me115.com/feed">订阅</a>] Github：<a href="https://github.com/me115">大CC</a></p>

<div class="ujian-hook"></div><div style='clear:both;'></div>

 
		<script type="text/javascript">
		var ujian_config = {
			'num':5,
			'showType':2,
			'bgColor':"",
			'mouseoverColor':"#E6F3DE",
			'textColor':"#333333",
			'hoverTextColor':"#333333",
			'borderColor':"#dddddd",
			'picSize':96,
			'target':1,
			'textHeight':60,
			'defaultPic':"",
			'itemTitle':"您可能喜欢："
		}</script>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>]]></content:encoded>
			<wfw:commentRss>http://blog.me115.com/2016/05/933/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>从C++到GO</title>
		<link>http://blog.me115.com/2016/01/926</link>
		<comments>http://blog.me115.com/2016/01/926#comments</comments>
		<pubDate>Tue, 26 Jan 2016 10:23:37 +0000</pubDate>
		<dc:creator>大CC</dc:creator>
				<category><![CDATA[GO语言]]></category>
		<category><![CDATA[go]]></category>
		<category><![CDATA[事件驱动]]></category>

		<guid isPermaLink="false">http://blog.me115.com/?p=926</guid>
		<description><![CDATA[从C++到GO 刚开始接触Go语言，看了两本Go语言的书，从c++开发者的角度来 &#8230;<p class="read-more"><a href="http://blog.me115.com/2016/01/926">继续阅读 &#187;</a></p>]]></description>
				<content:encoded><![CDATA[<h1 id="-c-go">从C++到GO</h1>

<p>刚开始接触Go语言，看了两本Go语言的书，从c++开发者的角度来看看go语言的新特性，说下自己感触较深的几点：</p>

<h2 id="-">并发编程</h2>

<p>Go语言层面支持协程，将并发业务逻辑从异步转为同步，大幅提高开发效率；   <br />在c++中，做并发编程目前主流的方案是事件驱动（单线程/多线程/多进程模型等)，而事件驱动就需要一个IO多路复用的分发器（select/epoll），这样，就造成了业务逻辑的断开，在代码层面为异步模型，比如：    <br />1).先是一段业务代码    <br />2).调用IO（业务断裂）    <br />3).IO完成后的后续处理逻辑；    <br />而go中的协程的支持让这样的开发工作就轻松多了，按照同步的方式顺序写业务逻辑，遇到IO也没关系，一个线程中可以创建成上百万个协程，这个协程阻塞了就跑下一个，不需要应用代码层面来负责IO后续调度的处理；    <br />比起自己用C/C++去封装底层或调用libevent之类的库，Go的优势是将事件机制封装成了CSP模式，编程变得方便了，但是需要付出goroutine调度的开销；    <br />ps1：Go语言标准库提供的所有系统调用操作（当然也包括所有同步IO 操作），都会出让CPU 给其他goroutine；    <br />ps2：看过网上的经验数据，同步和异步的开发效率(不是运行效率，指的是出活速度)差不多是4:1，嘿嘿，这个数据好激动~~    <br />关于事件驱动与协程在处理并发上的对比，详见不鳥萬Rio的回答：    <br /><a href="https://www.zhihu.com/question/19585576/answer/12424447">https://www.zhihu.com/question/19585576/answer/12424447</a></p>

<h2 id="-">垃圾回收</h2>

<p>毫无疑问这个好用，有了垃圾回收，不需要开发者自行控制内存的释放，这样可避免一堆问题（重复释放、忘记释放内存、访问已释放的内存等）；   <br />当然，c++11引入的智能指针（unique_ptr等）如果在程序中应用的普遍，也可以达到类似垃圾回收的目的；    <br />GC带来的问题也是有的，会造成STW，会有程序停止调度的卡顿；    <br />Go1.5的GC利用各种手段大大缩减了STW的时间。Go语言官方保证，在50毫秒的Go程序运行时间中因GC导致的调度停顿至多只有10毫秒。    <br />（ref：<a href="http://www.infoq.com/cn/articles/2015-review-go）">http://www.infoq.com/cn/articles/2015-review-go）</a></p>

<h2 id="-">函数多返回值</h2>

<p>这在python里算不得什么新鲜事，但对c++来说，要实现函数返回多个数据，要么封装一个结构体，要不就只能通过函数传参实现；   <br />多返回值这玩意，在码字的时候能提升心情愉悦感啊，想想，在要返回多个值的场景，不用再找个地方用一个结构体封装一下，直接返回，多直接：    <br />func getName()(firstName, middleName, lastName, nickName string){    <br />return &quot;May&quot;, &quot;M&quot;, &quot;Chen&quot;, &quot;Babe&quot;    <br />}</p>

<h2 id="-">错误处理</h2>

<p>提到多返回值，就接着说说错误处理，估计多返回值应用最多的场景就是第二个参数传回函数的错误状态；比如以下写法就很常见了：   <br />if result, ok := moreMagic(); ok {    <br />/<em> Do something with result </em>/    <br />}    <br />c/c++对错误的处理一般都是通过错误码来确定一个函数是否正确调用，因此相比c/c++而言，go的错误处理代码行减少了，看上去也美观优雅；    <br />go引入了3个关键字（defer、panic和    <br />recover）用于标准的错误处理流程；defer关键字的引入，保证错误处理的代码在发现错误时一定能够被调用，不会因为业务分支逻辑上的修改而漏调；</p>

<p>当然，看和谁比了，python的实践者认为没有使用try catch的异常处理机制，让错误处理显得很繁琐；   <br />Russ Cox指出Go语言是为大型软件设计的，Go语言的返回错误方式，不可否认，对于调用者不是很方便，但这样做会让程序中可能会出错的地方显的很明显。对于小程序来说，你可能只想打印出错误，退出程序。对于一些很精密的程序，根据异常的不同，来源的不同，程序会做出不同的反应，这很常见，这种情况中，try + catch的方式相对于错误返回模式显得冗长。    <br />ref：    <br />Go语言的错误处理机制引发争议    <br /><a href="http://www.infoq.com/cn/news/2012/11/go-error-handle">http://www.infoq.com/cn/news/2012/11/go-error-handle</a></p>

<h2 id="-">函数的地位提升</h2>

<p>函数作为“类型”出现，成为了一等公民；可以定义函数类型，将一个函数赋值给函数变量，然后在业务链中传递，这个在c++中只有使用std::function才能做到；   <br />还可以使用匿名函数（对应c++11中的lambda表达式），在语言层面支持函数编程，从而可以对程序进行更加灵活的控制和管理。</p>

<h2 id="-">强制的编码规范</h2>

<p>系统做大做久了，代码质量难免下降；开发人员的代码风格不一致，导致程序中充斥着千奇百怪的命名及类的组织方式；   <br />是的，是个公司就会有代码规范，但那只是写在纸面上的东西，是否真照着执行了，还真不好说；什么后期扫描，不改不给上线？    <br />为工程而生，go强制的编码规范，让人耳目一新，从命名、到代码排列组织方式都有明确的规定，不符合就不能编译通过！这个真得叫好；代码工程不是实现个性张扬的地方；</p>

<h2 id="-">语法后置，为啥这么搞？</h2>

<p>以上聊到的都是go的优点，看一个爽一个；但go的语法，如变量、函数的声明和定义，和我们常见的语言语法相比，都是类型后置，这点着实有些不习惯；   <br />为啥要这么搞？    <br />Rob Pike(go语言的创建者之一)针对这个问题给过解释:不是为了与众不同，而是为了更加清晰易懂。特别是当类型比较复杂时，Go的类型语法要比 C 的容易懂。    <br />详见：    <br /><a href="https://www.zhihu.com/question/21656696/answer/19027040">https://www.zhihu.com/question/21656696/answer/19027040</a></p>

<p>最后，贴几点Go语言的哲学：   <br />Go语言集众多编程范式之所长，并以自己独到的方式将它们融合在一起。程序员们可以用他们喜欢的风格去设计程序。    <br />相对于设计规则上的灵活，Go语言有着明确且近乎严格的编码规范。我们可以通过“go fmt”命令来按照官方的规范格式化代码。    <br />Go语言是强调软件工程的编程语言。它自带了非常丰富的标准命令，涵盖了软件生命周期（开发、测试、部署、维护等等）的各个环节。    <br />Go语言是云计算时代的编程语言。它关注高并发程序，并旨在开发效率和运行效率上取得平衡。    <br />Go语言提倡交换数据，而不是共享数据。它的并发原语Goroutine和Channel是其中的两大并发编程利器。同时，Go语言也提供了丰富的同步工具，以供程序员们根据场景选用。然而，后者就不属于语言级别的支持了。    <br /><a href="http://www.infoq.com/cn/articles/go-language-introduction">http://www.infoq.com/cn/articles/go-language-introduction</a></p>

<p>Posted by: 大CC | 26JAN,2016   <br />博客：<a href="http://blog.me115.com">blog.me115.com</a> [<a href="http://blog.me115.com/feed">订阅</a>]    <br />Github：<a href="https://github.com/me115">大CC</a></p>

<div class="ujian-hook"></div><div style='clear:both;'></div>

 
		<script type="text/javascript">
		var ujian_config = {
			'num':5,
			'showType':2,
			'bgColor':"",
			'mouseoverColor':"#E6F3DE",
			'textColor':"#333333",
			'hoverTextColor':"#333333",
			'borderColor':"#dddddd",
			'picSize':96,
			'target':1,
			'textHeight':60,
			'defaultPic':"",
			'itemTitle':"您可能喜欢："
		}</script>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>]]></content:encoded>
			<wfw:commentRss>http://blog.me115.com/2016/01/926/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>网络编程中的关键问题总结</title>
		<link>http://blog.me115.com/2015/12/924</link>
		<comments>http://blog.me115.com/2015/12/924#comments</comments>
		<pubDate>Thu, 31 Dec 2015 08:18:14 +0000</pubDate>
		<dc:creator>大CC</dc:creator>
				<category><![CDATA[网络编程]]></category>
		<category><![CDATA[epoll]]></category>

		<guid isPermaLink="false">http://blog.me115.com/?p=924</guid>
		<description><![CDATA[网络编程中的关键问题总结 总结下网络编程中关键的细节问题，包含连接建立、连接断开 &#8230;<p class="read-more"><a href="http://blog.me115.com/2015/12/924">继续阅读 &#187;</a></p>]]></description>
				<content:encoded><![CDATA[<h1 id="-">网络编程中的关键问题总结</h1>

<p>总结下网络编程中关键的细节问题，包含连接建立、连接断开、消息到达、发送消息等等；</p>

<h2 id="-">连接建立</h2>

<p>包括服务端接受 (accept) 新连接和客户端成功发起 (connect) 连接。    <br />accept接受连接的问题在本文最后会聊到，这里谈谈connect的关键点；     <br />使用非阻塞连接建立需要注意：     <br />connect/select返回后，可能没有连接上；需要再次确认是否成功连接；</p>

<p>步骤为：</p>

<ol>   <li>使用异步connect直接连接一次，因为使用了非阻塞，函数立刻返回； </li>    <li>检查返回值，为0成功连接，否则加入到select/epoll中监控； </li>    <li>当有写事件时，连接成功；当即可读又可写时，可能是有错误或者连接成功后有数据已经发过来；所以，此时，需要用getsockopt()读取socket的错误选项，二次确认是否真的连接成功: </li> </ol>

<pre><code>Fcntl(sockfd, F_SETFL, flags | O_NONBLOCK);
error = 0;
if ( (n = connect(sockfd, saptr, salen)) &lt; 0)
    if (errno != EINPROGRESS)
        return(-1);

/* Do whatever we want while the connect is taking place. */
if (n == 0)
    goto done;    /* connect completed immediately */

if ( (n = Select(sockfd+1, &amp;rset, &amp;wset, NULL,
                 nsec ? &amp;tval : NULL)) == 0) {
    close(sockfd);        /* timeout */
    errno = ETIMEDOUT;
    return(-1);
}

if (FD_ISSET(sockfd, &amp;rset) || FD_ISSET(sockfd, &amp;wset)) {
    len = sizeof(error);
            //二次确认是否真的连接成功
    if (getsockopt(sockfd, SOL_SOCKET, SO_ERROR, &amp;error, &amp;len) &lt; 0)
        return(-1);            /* Solaris pending error */
} else
    err_quit(&quot;select error: sockfd not set&quot;);</code></pre>

<h2 id="-">连接断开</h2>

<p>包括主动断开 (close 或 shutdown) 和被动断开 (read 返回 0)。 </p>

<p>当打算关闭网络连接时，如何能知道对方已经发送了数据自己还没有收到？ 
  <br />在TCP层面解决：主动关闭的时候只使用半关闭shutdown(), 这样，服务端这边之时关闭了写端，还可以正常读；客户端收到关闭的信号后（read返回0），会再调用shutdown关闭整个连接； 

  <br />在应用层面解决：双方通过某个标记协商，在标记之后不再读写数据，这样就可以完全的关闭连接了；</p>

<p>关闭连接时需要注意的： 
  <br />是否还有未发送的数据，需要保证应用缓冲区中的数据都发送完毕之后再关闭缓冲区； 

  <br />TCP缓存区不用我们考虑，因为在调用shutdown或close的时候，TCP的实现是会将TCP的发送缓冲区中的数据都发送出去，然后再发送FIN报文(也可能是组合成一个报文发送）；</p>

<h2 id="-">消息到达</h2>

<p>消息到达是最重要的事件；对它的处理决定了网络编程的风格:是阻塞还是非阻塞、分包的处理、应用层的缓冲如何设计等等；</p>

<h3 id="-">处理分包</h3>

<p>所谓分包，就是在一个个字节流消息中如何区分出一个个消息来； 
  <br />常见的分包方法有：</p>

<ol>
  <li>固定长度； </li>

  <li>特殊的结尾符，比如字符串的 ，或者回车换行等； </li>

  <li>固定的消息头中指定后续的消息的长度，然后跟上一个消息体内容； </li>

  <li>使用协议本身的格式，比如json格式头尾配对（XML也一样）； </li>
</ol>

<h3 id="-">字节序转换注意字节对齐</h3>

<p>如果传输的是二进制类型，在字节流的缓存区中直接强转可能core dump；因为有的系统访问地址需要字节对齐，不能在任意地址上访问二进制类型（如整形），合理的方式是将其copy到一个本地变量中，然后再做字节序的转换：</p>

<pre><code>int32_t peekInt32() const
{
    assert(readableBytes() &gt;= sizeof(int32_t));
    int32_t be32 = 0;
    ::memcpy(&amp;be32,readerIndex_, sizeof(be32) );
    return be32toh(be32);
}</code></pre>

<h3 id="-">应用层缓存区的实现</h3>

<p>数据到达时处理需要注意： 
  <br />socket读事件来到，必须一次将所有的数据都读完，否则会造成一直有可读事件，造成busy-loop；读到的数据当然就需要有个应用层的缓冲区来存放； 

  <br />因为应用的缓存区是有限的，可以默认设置一个大小，比如2kb，或者根本就不设置初始大小，用多少分配多少；muduo中使用的是vector<char> 来作为缓存区，可以动态增长；</p>

<p>muduo buffer使用的技巧： 
  <br />buffe采用了vector<char>自动增长的数据结构； 

  <br />从系统内核中调用的时候，在应用层需要有足够大的缓冲区，最好能一次将系统recv到的缓冲区给读空，一次系统调用就搞定一切事情； 

  <br />而应用缓冲区考虑到有很多个并发的可能，针对每个连接一次都分配较大的缓冲区浪费严重，陈硕推荐使用readv一次读入到两个地址中，首先将第一个地址填满，如果还有更多数据，就写入到临时缓冲区中，然后append到应用缓冲区；</p>

<p>读的时候使用readv，局部使用一个足够大的额外空间（64KB），这样，一次读取就足以将socket中的缓存区读空（一般不会超过64K，tcp buffer如果确实要设置大的缓存区，需要调整系统参数）；如果数据不多，可能内部buffer就装下了，没有额外操作，否则，多的数据读到了外部的缓存区，再append到内部缓存区：</p>

<pre><code>ssize_t Buffer::readFd(int fd, int* savedErrno)
{
  // saved an ioctl()/FIONREAD call to tell how much to read
  char extrabuf[65536];
  struct iovec vec[2];
  const size_t writable = writableBytes();
  vec[0].iov_base = begin()+writerIndex_;
  vec[0].iov_len = writable;
  vec[1].iov_base = extrabuf;
  vec[1].iov_len = sizeof extrabuf;
  // when there is enough space in this buffer, don't read into extrabuf.
  // when extrabuf is used, we read 128k-1 bytes at most.
  const int iovcnt = (writable &lt; sizeof extrabuf) ? 2 : 1;
  //只有一次系统调用：这里的实现比较巧妙
  const ssize_t n = sockets::readv(fd, vec, iovcnt);
  if (n &lt; 0)
  {
    *savedErrno = errno;
  }
  else if (implicit_cast&lt;size_t&gt;(n) &lt;= writable)
  {
    writerIndex_ += n;
  }
  else
  {
    writerIndex_ = buffer_.size();
    append(extrabuf, n - writable);
  }
  // if (n == writable + sizeof extrabuf)
  // {
  //   goto line_30;
  // }
  return n;
}</code></pre>

<h2 id="-">发送消息</h2>

<p>网络编程中数据发送比数据接受要难处理； 
  <br />数据的接收，只需要peek足够的数据后，就可以从应用缓冲区接收出来，然后处理；而数据的发送，还需要考虑对方接受缓慢的情况，导致tcp发送缓冲区累积，最终导致应用缓冲区累积；</p>

<p>举个例子：某客户端对echo服务器只发送，但故意不接收； 
  <br />客户端如果只是发送，但从不接收的话，那么这边发送过去的报文，首先会导致客户端的tcp接收缓冲区满，然后通过ack报文告诉服务器端，这边的滑动窗口为0了，不能再发了；后续客户端发送的报文就把服务器端TCP发送缓冲区积满，然后累积应用层的发送缓冲区（因为是非阻塞），最终导致服务端的应用缓存区满或者内存撑爆；</p>

<p>需要发送数据的时候，优先直接调用write()发送，如果发送不成功，或没有全部发送完毕，才加入到发送缓存区,等待可写事件到来后发送； 
  <br />直接调用write()发送数据时，需要先将本次需要发送的数据添加到缓存区，然后发送缓存区，不可直接发送本次数据（因为缓存区中可能有遗留的数据未发送完）</p>

<pre><code>void TcpConnection::handleWrite()
{
  loop_-&gt;assertInLoopThread();
  if (channel_-&gt;isWriting())
  {
      //注意，这里只调用了一次write,而没有反复调用write直到出现EAGAIN错误，
      //原因是如果第一次调用没有发送完全部的数据，第二次调用几乎肯定是EAGAIN错误，
      //因此这里减少了一次系统调用，这么做不影响正确性，却能够降低系统时延
    ssize_t n = sockets::write(channel_-&gt;fd(),
                               outputBuffer_.peek(),
                               outputBuffer_.readableBytes());
    if (n &gt; 0)
    {
      outputBuffer_.retrieve(n);
      if (outputBuffer_.readableBytes() == 0)
      {
          //如果发送缓存区为空，不再关注写事件，避免 busy loop 
        channel_-&gt;disableWriting();
        //如果还有写完成之后的回调，加入待执行回调队列
        if (writeCompleteCallback_)
        {
          loop_-&gt;queueInLoop(boost::bind(writeCompleteCallback_, shared_from_this()));
        }
        //如果此时正在关闭，调用shutdownInLoop 继续执行关闭过程
        if (state_ == kDisconnecting)
        {
          shutdownInLoop();
        }
      }
    }
    else
    {
      LOG_SYSERR &lt;&lt; &quot;TcpConnection::handleWrite&quot;;
      // if (state_ == kDisconnecting)
      // {
      //   shutdownInLoop();
      // }
    }
  }
  else
  {
    LOG_TRACE &lt;&lt; &quot;Connection fd = &quot; &lt;&lt; channel_-&gt;fd()
              &lt;&lt; &quot; is down, no more writing&quot;;
  }
}</code></pre>

<h2 id="-">消息发送完毕</h2>

<p>对于低流量的服务，可以不必关心这个事件；另外，这里“发送完毕”是指将数据写入操作系统的缓冲区，后续由 TCP 协议栈负责数据的发送与重传，不代表对方已经收到数据。</p>

<h2 id="-">其它问题</h2>

<h3 id="io-multiplexing-">IO multiplexing 是否可以配合阻塞套接字使用？</h3>

<p>一般都配合非阻塞socket使用，如果使用阻塞IO，可能在读写事件上阻塞当前线程，造成无法继续处理已经就绪的事件； 
  <br />初学网络编程可能都会有这个想法，select返回后，如果是读事件，那么这时候tcp读缓冲区肯定是有数据，这时即使使用阻塞套接字来read，应该也不会阻塞；但这样忽略了一个点，缓冲区确实是有数据，但是很可能到达的数据并不满足你要求读的数据大小，这样read调用还是会阻塞，直到有足够的数据才返回； 

  <br />那么，对于数据读不可以，对accept()总可以吧，连接事件返回，一般都是有新用户接入，这时候阻塞的accept()应该总是能够返回；但在某些情况下，可能对方刚连接上就断开了，并给服务端发送了一个RST请求，造成服务端这边将已经就绪的连接请求又移除了，这样的场景下，select返回，但是accept却无法获取新的连接，造成阻塞，直到下一个连接请求到来；(这方面的例子详见《UNIX网络编程卷1：套接字联网API》16.6节非阻塞accept() ) 

  <br />所以任何时候，IO multiplexing都需要配合非阻塞IO使用；</p>

<h3 id="-">零拷贝的实现</h3>

<p>对于内核层的实现，底层调用的是系统调用sendFile()方法； 
  <br />zerocopy技术省去了将操作系统的read buffer拷贝到程序的buffer, 以及从程序buffer拷贝到socket buffer的步骤, 直接将 read buffer 拷贝到 socket buffer； 

  <br /><img style="border-bottom: 0px; border-left: 0px; display: inline; border-top: 0px; border-right: 0px" title="image" border="0" alt="image" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/image5.png" width="350" height="312" /> 

  <br />详见：<a href="http://www.cnblogs.com/zemliu/p/3695549.html">http://www.cnblogs.com/zemliu/p/3695549.html</a></p>

<p>应用层上的实现，对于自定义的结构，一般是交换内部指针（使用C++11，可以使用move操作来实现高效交换结构体） 
  <br />如果是vector等结构，使用其成员函数swap()就能达到高效的交换（类似C++11中的move操作）； 

  <br />例如muduo中buffer实现：通过swap实现了缓存区的指针交换，从而达到数据交换的目的，而不用拷贝缓冲区；</p>

<pre><code>void swap(Buffer&amp; rhs)
{
    buffer_.swap(rhs.buffer_); // std::vector&lt;char&gt; buffer_;
    std::swap(readerIndex_, rhs.readerIndex_);
    std::swap(writerIndex_, rhs.writerIndex_);
}</code></pre>

<h3 id="epoll-lt">epoll使用LT</h3>

<p>epoll使用是LT而非ET，原因如下：</p>

<ol>
  <li>LT编程方便，select的经验都可同样适用； </li>

  <li>读的时候只需要一次系统调用，而ET必须读到EAGAIN错误；减少一次系统调用，降低时延； </li>
</ol>

<p>一般认为 edge-trigger 模式的优势在于能够减少 epoll 相关系统调用，这话不假，但网络服务程序里可不是只有 epoll 相关系统调用，为了绕过饿死问题，edge-trigger 模式下用户要自行进行 read/write 循环处理，这其中增加的系统调用和减少的 epoll 系统调用加起来，总体性能收益究竟如何？只有实际测量才知道，无法一概而论。为了降低处理逻辑复杂度，常用的事件处理库大部分都选择了 level-trigger 模式（如 libevent、boost::asio、muduo等）</p>

<h2 id="-">参考</h2>

<p>《UNIX网络编程卷1：套接字联网API》 
  <br />《Linux多线程服务端编程：使用muduo网络库》 

  <br /><a href="http://www.cnblogs.com/zemliu/p/3695549.html">http://www.cnblogs.com/zemliu/p/3695549.html</a></p>

<p>Posted by: 大CC | 31DEC,2015 
  <br />博客：<a href="http://blog.me115.com">blog.me115.com</a> [<a href="http://blog.me115.com/feed">订阅</a>] 

  <br />Github：<a href="https://github.com/me115">大CC</a></p>

<div class="ujian-hook"></div><div style='clear:both;'></div>

 
		<script type="text/javascript">
		var ujian_config = {
			'num':5,
			'showType':2,
			'bgColor':"",
			'mouseoverColor':"#E6F3DE",
			'textColor':"#333333",
			'hoverTextColor':"#333333",
			'borderColor':"#dddddd",
			'picSize':96,
			'target':1,
			'textHeight':60,
			'defaultPic':"",
			'itemTitle':"您可能喜欢："
		}</script>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>]]></content:encoded>
			<wfw:commentRss>http://blog.me115.com/2015/12/924/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Reactor事件驱动的两种实现：面向对象 VS 函数式编程</title>
		<link>http://blog.me115.com/2015/12/907</link>
		<comments>http://blog.me115.com/2015/12/907#comments</comments>
		<pubDate>Wed, 30 Dec 2015 07:00:21 +0000</pubDate>
		<dc:creator>大CC</dc:creator>
				<category><![CDATA[网络编程]]></category>
		<category><![CDATA[muduo]]></category>
		<category><![CDATA[Reactor]]></category>

		<guid isPermaLink="false">http://blog.me115.com/?p=907</guid>
		<description><![CDATA[Reactor事件驱动的两种实现：面向对象 VS 函数式编程 这里的函数式编程的 &#8230;<p class="read-more"><a href="http://blog.me115.com/2015/12/907">继续阅读 &#187;</a></p>]]></description>
				<content:encoded><![CDATA[<h1 id="reactor-vs-">Reactor事件驱动的两种实现：面向对象 VS 函数式编程</h1>

<p>这里的函数式编程的设计以muduo为例进行对比说明；</p>

<h2 id="reactor-">Reactor实现架构对比</h2>

<p>面向对象的设计类图如下：</p>

<p>&#160;<a href="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/oo_class1.jpg" target="_blank"><img style="border-bottom: 0px; border-left: 0px; display: inline; border-top: 0px; border-right: 0px" title="oo_class" border="0" alt="oo_class" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/oo_class_thumb.jpg" width="1012" height="598" /></a>     <br /></p>

<p>函数式编程以muduo为例，设计类图如下：</p>

<p><a href="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/muduo1.jpg" target="_blank"><img style="border-bottom: 0px; border-left: 0px; display: inline; border-top: 0px; border-right: 0px" title="muduo" border="0" alt="muduo" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/muduo_thumb.jpg" width="1022" height="1019" /></a>&#160; <br /></p>

<h2 id="-reactor-">面向对象的Reactor方案设计</h2>

<p>我们先看看面向对象的设计方案，想想为什么这么做；   <br />拿出Reactor事件驱动的模式设计图，对比来看，清晰明了；</p>

<p>&#160;<img style="border-bottom: 0px; border-left: 0px; display: inline; border-top: 0px; border-right: 0px" title="reactor_model" border="0" alt="reactor_model" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/reactor_model.jpg" width="967" height="455" />&#160; <br /></p>

<p>从左边开始，事件驱动，需要一个事件循环和IO分发器，EventLoop和Poller很好理解；为了让事件驱动支持多平台，Poller上加一个继承结构，实现select、epoller等IO分发器选用；</p>

<p>Channel是要监听的事件封装类，核心成员：fd文件句柄；   <br />成员方法围绕着fd展开展开，如关注fd的读写事件、取消关注fd的读写事件；    <br />核心方法：    <br />enableReading/Writing;    <br />disableReading/Writing;    <br />以及事件到来后的处理方法：    <br />handleEvent；    <br />在OO设计这里，handleEvent设计成一个虚函数，回调上层实际的数据处理；</p>

<p>AcceptChannel和ConnetionChannel派生自Channel，负责实际的网络数据处理；根据职责的不同而区分，AcceptChannel用于监听套接字，接收新连接请求；有新的请求到来时，生成新的socket并加入到事件循环，关注读事件；   <br />ConnetionChannel用于真实的用户数据处理，处理用户的读写请求；涉及到具体的数据处理，当然，在这里会需要用到应用层的缓存区；</p>

<p>比较困难的是用户逻辑层的设计；放在哪里合适？   <br />先看看需求，用户逻辑层需要知道的事件点（在这之后可能会有应用层的逻辑）：    <br />连接建立、消息到来、消息发送完毕、连接关闭；    <br />这四个事件的源头是Channel的handleEvent()，直接调用者应该Channel的派生类（AcceptChannel和ConnetionChannel），貌似可以将用户逻辑层的指针放到Channel里；    <br />且不说架构上是否合理，单是实现上右边Channel这一块（含AcceptChannel和ConnetionChannel）对用户是透明的，用户只需要关注以上四个事件点，底层的细节用户层并不关心（比如是否该在事件循环中关注某个事件，取消关注某个事件，对用户都是透明的），所以外部用户无法直接将用户逻辑层的指针给Channel；</p>

<p>想想用户与网络库的接口在哪里？   <br />IO分发器对用户也是透明的，用户可见就是EventLoop，在main方法中：</p>

<pre><code>EventLoop loop; 
loop.loop();</code></pre>

<p>用户逻辑层也就只有通过EventLoop与Channel的派生类关联上；
  <br />这样，就形成的最终的设计类图，在main方法中：</p>

<pre><code>UserLogicCallBack callback;
EventLoop loop(&amp;callback); //在定义 EventLoop时，将callback的指针传入，供后续使用；
loop.loop();</code></pre>

<p>而网络层调用业务层代码时，则通过eventloop_的过渡调用到业务逻辑的函数；
  <br />比如ConnetionChannel中数据到达的处理：</p>

<pre><code>eventloop_-&gt;getCallBack()-&gt;onMessage(this);</code></pre>

<h2 id="-reactor-">函数式编程的Reactor设计</h2>

<p>函数式编程中，类之间的关系主要通过组合来实现，而不是通过派生实现；
  <br />整个类图中仅有Poller处使用了继承关系；其它的都没有使用；

  <br />这也是函数式编程的一个设计理念，更多的使用组合而不是继承来实现类之间的关系，而支撑其能够这样设计的根源在于function()+bind()带来的函数自由传递，实现回调非常简单；

  <br />而OO设计中，只能使用基于虚函数/多态来实现回调，不可避免的使用继承结构;</p>

<p>下面再看看各个类的实现；
  <br />事件循环EventLoop和IO分发器没有区别；

  <br />Channel的职责也和上面类似，封装事件，所不同的是，Channel不再是继承结构中的基类，而是作为一个实体；

  <br />这样，handleEvent方法就不再是一个纯虚函数，而是包含具体的逻辑处理，当然，只有最基本的事件判断，然后调用上层的读写回调：</p>

<pre><code>void Channel::handleEvent()
{
  if (revents_ &amp; (POLLIN | POLLPRI | POLLRDHUP))
  {
    if (readCallback_) readCallback_();
  }
  if (revents_ &amp; POLLOUT)
  {
    if (writeCallback_) writeCallback_();
  }
}</code></pre>

<p>这样的关键是设置一堆回调函数，通过boost::function()+boost::bind()可以轻松的做到；</p>

<h3 id="acceptor-tcpconnection">Acceptor 和TcpConnection</h3>

<p>Acceptor类，这个对应到上面的AcceptChannel，但实现不是通过继承，而是通过组合实现；
  <br />Acceptor用于监听，关注连接，建立连接后，由TCPConnection来接管处理；

  <br />这个类没有业务处理，用来处理监听和连接请求到来后的逻辑；

  <br />所有与事件循环相关的都是channel，Acceptor不直接和EventLoop打交道，所以在这个类中需要有一个channel的成员，并包含将channel挂到事件循环中的逻辑（listen()）；

  <br />TcpConnection,处理连接建立后的收发数据；业务处理回调完成；</p>

<h3 id="tcpserver">TCPServer</h3>

<p>TCPServer就是胶水，作用有二：</p>

<ol>
  <li>作为最终用户的接口方，和外部打交道通过TCPServer交互，而业务逻辑处理将回调函数传入到底层，这种传递函数的方式犹如数据的传递一样自然和方便； </li>

  <li>作用Acceptor和TcpConnection的粘合剂，调用Acceptor开始监听连接并设置回调，连接请求到来后，在回调中新建TcpConnection连接，设置TcpConnection的回调（将用户的业务处理回调函数传入，包括：连接建立后，读请求处理、写完后的处理，连接关闭后的处理），从这里可以看到，业务逻辑的传递就跟数据传递一样，多么漂亮； </li>
</ol>

<h2 id="-">示例对比</h2>

<p>通过一个示例来体会这两种实现中回调实现的差别；
  <br />示例：分析读事件到来时，底层如何将消息传递给用户逻辑层函数来处理的？</p>

<h3 id="oo-">OO实现</h3>

<p>channel作为事件的监听接口，加入到事件循环中，当读事件到来时，需要调用
  <br />ConnetionChannel上的handleEvent();而异步数据的读请求最终需要业务逻辑层来判断是否读到相应的数据，这就需要从ConnetionChannel中调用用户逻辑层上的OnMessage();

  <br />看看这段逻辑的OO实现序列图：</p>

<p><a href="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/oo_seq_msg1.jpg" target="_blank"><img style="border-bottom: 0px; border-left: 0px; display: inline; border-top: 0px; border-right: 0px" title="oo_seq_msg" border="0" alt="oo_seq_msg" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/oo_seq_msg_thumb.jpg" width="922" height="732" /></a>&#160; <br /></p>

<p>代码层面的实现：
  <br />定义用户逻辑处理类UserLogicCallBack，接收消息的处理函数为onMessage()；

  <br />我们关注最终底层是如何调用到业务逻辑层的onMessage()的；</p>

<pre><code>int main()
{
    UserLogicCallBack urlLogic;
    EventLoop loop(urlLogic);//将用户逻辑对象与事件循环对象关联起来
    loop.loop();
}</code></pre>

<p>callback_用户逻辑层的对象在EventLoop初始化时传入：</p>

<pre><code>class EventLoop{
    EventLoop(CallBack &amp; callback):
        callback_(callback)
    {
    }
    CallBack* getCallBack()
    {
        return &amp;callback_;
    }
    CallBack&amp; callback_; //回调方法基类
}</code></pre>

<p>当读事件到来，在ConnectionChannel中通过eventloop对象作为桥梁，回调消息业务处理onMesssage();</p>

<pre><code>void ConnectionChannel::handleRead(){
      int savedErrno = 0;
    //返回缓存区可读的位置，返回所有读到的字节,具体到是否收全，
    //是否达到业务需要的数据字节数，由业务层来判断处理
    ssize_t n = inputBuffer_.readFd(fd_, &amp;savedErrno);
    if (n &gt; 0)
    {    
                //通过eventloop作为中介，调用业务层的回调逻辑
        loop_-&gt;getCallBack()-&gt;onMesssage(this,&amp;inputBuffer_);
    }
    else if (n == 0)
    {
        handleClose();
    }
    else
    {
        errno = savedErrno;
        handleError();
    }
}</code></pre>

<h3 id="-">函数式编程实现</h3>

<p>而muduo的回调，使用boost::function()+boost::bind()实现，通过这两个神器，将使用者和实现者解耦；
  <br />通过TcpServer，将用户逻辑层的函数传递到底层；读事件到来，回调用户逻辑；</p>

<p>以下是时序</p>

<p><a href="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/fun_seq_msg1.jpg" target="_blank"><img style="border-bottom: 0px; border-left: 0px; display: inline; border-top: 0px; border-right: 0px" title="fun_seq_msg" border="0" alt="fun_seq_msg" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/fun_seq_msg_thumb.jpg" width="727" height="565" /></a>&#160; <br /></p>

<p>代码层面，我们看看用户逻辑层的代码是如何传入的：
  <br />UserLogicCallBack中包含TcpServer的对象；</p>

<pre><code>TcpServer server_;</code></pre>

<p>在构造函数中，将onMessage传递给TcpServer，这是第一次传递： </p>

<pre><code>UserLogicCallBack::UserLogicCallBack(muduo::net::EventLoop* loop,
                       const muduo::net::InetAddress&amp; listenAddr)
  : server_(loop, listenAddr, &quot;UserLogicCallBack&quot;)
{
  server_.setConnectionCallback(
      boost::bind(&amp;UserLogicCallBack::onConnection, this, _1));
  //这里将onMessage传递给TcpServer
  server_.setMessageCallback(
      boost::bind(&amp;UserLogicCallBack::onMessage, this, _1, _2, _3));
}</code></pre>

<p>TcpServer中的相关细节：</p>

<pre><code>class TcpServer{
    void setMessageCallback(const MessageCallback&amp; cb)
    { messageCallback_ = cb; }

    typedef boost::function&lt;void (const TcpConnectionPtr&amp;,
                                  Buffer*,
                                  Timestamp)&gt; MessageCallback;
    MessageCallback messageCallback_;
};</code></pre>

<p>TcpServer新建连接时，将用户层的回调函数继续往底层传递，这是第二次传递：</p>

<pre><code>void TcpServer::newConnection(int sockfd, const InetAddress&amp; peerAddr)
{
  TcpConnectionPtr conn(new TcpConnection(ioLoop,
                                          connName,
                                          sockfd,
                                          localAddr,
                                          peerAddr));
  conn-&gt;setConnectionCallback(connectionCallback_);
  // 这里将onMessage()传递给TcpConnection
  conn-&gt;setMessageCallback(messageCallback_); 
  conn-&gt;setWriteCompleteCallback(writeCompleteCallback_);
  conn-&gt;setCloseCallback(boost::bind(&amp;TcpServer::removeConnection, this, _1)); 
  ioLoop-&gt;runInLoop(boost::bind(&amp;TcpConnection::connectEstablished, conn));
}</code></pre>

<p>通过这两次传递，messageCallback_作为成员变量保存在TcpConnection中；
  <br />当读事件到来时，TcpConnection中就可以直接调用业务层的回调逻辑：</p>

<pre><code>void TcpConnection::handleRead(Timestamp receiveTime)
{
  //返回缓存区可读的位置，返回所有读到的字节,具体到是否收全，
  //是否达到业务需要的数据字节数，由业务层来判断处理
  ssize_t n = inputBuffer_.readFd(channel_-&gt;fd(), &amp;savedErrno);
  if (n &gt; 0)
  {
    //回调业务层的逻辑
    messageCallback_(shared_from_this(), &amp;inputBuffer_, receiveTime);
  }
  else if (n == 0)
  {
    handleClose();
  }
  else
  {
    errno = savedErrno;
    handleError();
  }
}</code></pre>

<p>完整时序详见最后一节；源代码来自muduo库；</p>

<h2 id="-">两者的时序图对比</h2>

<p>Reactor的面向对象编程时序：</p>

<p>&#160;<a href="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/oo_sequence1.jpg" target="_blank"><img style="border-bottom: 0px; border-left: 0px; display: inline; border-top: 0px; border-right: 0px" title="oo_sequence" border="0" alt="oo_sequence" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/oo_sequence_thumb.jpg" width="1060" height="930" /></a> </p>

<p>&#160;</p>

<p>Reacotr的函数式编程时序：</p>

<p><a href="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/EchoServer_sequence1.jpg" target="_blank"><img style="border-bottom: 0px; border-left: 0px; display: inline; border-top: 0px; border-right: 0px" title="EchoServer_sequence" border="0" alt="EchoServer_sequence" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/EchoServer_sequence_thumb.jpg" width="1246" height="1401" /></a>&#160; <br /></p>

<h2 id="-">结论</h2>

<p>在面向对象的设计中，事件底层回调上层逻辑，本来和loop这个发送机没有任何关系的一件事，却需要使用它来作为中转；EventLoop作为回调的中间桥梁，实在是迫不得已的实现；
  <br />而muduo的设计中加入了TcpServer这一胶水层，整个架构就清晰多了；

  <br />boost::function()+boost::bind()让我们在回调的实现上有了更大的自由度，不用再依赖于基于虚函数的多态继承结构；但更大的自由度，也更容易带来糟糕的设计，使用boost::function()+boost::bind()基于对象的设计，还需要多多体会，熟练应用；</p>

<p>Posted by: 大CC | 30DEC,2015
  <br />博客：<a href="http://blog.me115.com">blog.me115.com</a> [<a href="http://blog.me115.com/feed">订阅</a>]

  <br />Github：<a href="https://github.com/me115">大CC</a></p>

<div class="ujian-hook"></div><div style='clear:both;'></div>

 
		<script type="text/javascript">
		var ujian_config = {
			'num':5,
			'showType':2,
			'bgColor':"",
			'mouseoverColor':"#E6F3DE",
			'textColor':"#333333",
			'hoverTextColor':"#333333",
			'borderColor':"#dddddd",
			'picSize':96,
			'target':1,
			'textHeight':60,
			'defaultPic':"",
			'itemTitle':"您可能喜欢："
		}</script>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>]]></content:encoded>
			<wfw:commentRss>http://blog.me115.com/2015/12/907/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>单线程你别阻塞，Redis时延问题分析及应对</title>
		<link>http://blog.me115.com/2015/12/891</link>
		<comments>http://blog.me115.com/2015/12/891#comments</comments>
		<pubDate>Wed, 09 Dec 2015 02:42:33 +0000</pubDate>
		<dc:creator>大CC</dc:creator>
				<category><![CDATA[Redis]]></category>
		<category><![CDATA[redis]]></category>
		<category><![CDATA[架构]]></category>

		<guid isPermaLink="false">http://blog.me115.com/?p=891</guid>
		<description><![CDATA[单线程你别阻塞，Redis时延场景分析及应对 Redis的事件循环在一个线程中处 &#8230;<p class="read-more"><a href="http://blog.me115.com/2015/12/891">继续阅读 &#187;</a></p>]]></description>
				<content:encoded><![CDATA[<h1 id="-redis-">单线程你别阻塞，Redis时延场景分析及应对</h1>

<p>Redis的事件循环在一个线程中处理，作为一个单线程程序，重要的是要保证事件处理的时延短，这样，事件循环中的后续任务才不会阻塞；    <br />当redis的数据量达到一定级别后（比如20G），阻塞操作对性能的影响尤为严重；     <br />下面我们总结下在redis中有哪些耗时的场景及应对方法；</p>

<h2 id="-">耗时长的命令造成阻塞</h2>

<h3 id="keys-sort-">keys、sort等命令</h3>

<p>keys命令用于查找所有符合给定模式 pattern 的 key，时间复杂度为O(N)， N 为数据库中 key 的数量。当数据库中的个数达到千万时，这个命令会造成读写线程阻塞数秒；    <br />类似的命令有sunion sort等操作；     <br />如果业务需求中一定要使用keys、sort等操作怎么办？</p>

<p><strong>解决方案：</strong>     <br /><img style="border-right-width: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px" title="image" border="0" alt="image" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/image.png" width="403" height="285" /> </p>

<p>在架构设计中，有“分流”一招，说的是将处理快的请求和处理慢的请求分离来开，否则，慢的影响到了快的，让快的也快不起来；这在redis的设计中体现的非常明显，redis的纯内存操作，epoll非阻塞IO事件处理，这些快的放在一个线程中搞定，而持久化，AOF重写、Master-slave同步数据这些耗时的操作就单开一个进程来处理，不要慢的影响到快的；    <br />同样，既然需要使用keys这些耗时的操作，那么我们就将它们剥离出去，比如单开一个redis slave结点，专门用于keys、sort等耗时的操作，这些查询一般不会是线上的实时业务，查询慢点就慢点，主要是能完成任务，而对于线上的耗时快的任务没有影响；</p>

<h3 id="smembers-">smembers命令</h3>

<p>smembers命令用于获取集合全集，时间复杂度为O(N),N为集合中的数量；    <br />如果一个集合中保存了千万量级的数据，一次取回也会造成事件处理线程的长时间阻塞；</p>

<p><strong>解决方案：</strong>     <br />和sort，keys等命令不一样，smembers可能是线上实时应用场景中使用频率非常高的一个命令，这里分流一招并不适合，我们更多的需要从设计层面来考虑；     <br />在设计时，我们可以控制集合的数量，将集合数一般保持在500个以内；     <br />比如原来使用一个键来存储一年的记录，数据量大，我们可以使用12个键来分别保存12个月的记录，或者365个键来保存每一天的记录，将集合的规模控制在可接受的范围；</p>

<p>如果不容易将集合划分为多个子集合，而坚持用一个大集合来存储，那么在取集合的时候可以考虑使用SRANDMEMBER key [count]；随机返回集合中的指定数量，当然，如果要遍历集合中的所有元素，这个命令就不适合了；</p>

<h3 id="save-">save命令</h3>

<p>save命令使用事件处理线程进行数据的持久化；当数据量大的时候，会造成线程长时间阻塞（我们的生产上，reids内存中1个G保存需要12s左右），整个redis被block；    <br />save阻塞了事件处理的线程，我们甚至无法使用redis-cli查看当前的系统状态，造成“何时保存结束，目前保存了多少”这样的信息都无从得知；</p>

<p><strong>解决方案：</strong>     <br />我没有想到需要用到save命令的场景，任何时候需要持久化的时候使用bgsave都是合理的选择（当然，这个命令也会带来问题，后面聊到）；</p>

<h2 id="fork-">fork产生的阻塞</h2>

<p>在redis需要执行耗时的操作时，会新建一个进程来做，比如数据持久化bgsave：    <br />开启RDB持久化后，当达到持久化的阈值，redis会fork一个新的进程来做持久化，采用了操作系统的copy-on-wirte写时复制策略，子进程与父进程共享Page。如果父进程的Page（每页4K）有修改，父进程自己创建那个Page的副本，不会影响到子进程；     <br />fork新进程时，虽然可共享的数据内容不需要复制，但会复制之前进程空间的内存页表，如果内存空间有40G（考虑每个页表条目消耗 8 个字节），那么页表大小就有80M，这个复制是需要时间的，如果使用虚拟机，特别是Xen虚拟服务器，耗时会更长；     <br />在我们有的服务器结点上测试，35G的数据bgsave瞬间会阻塞200ms以上；</p>

<p>类似的，以下这些操作都有进程fork；</p>

<ul>   <li>Master向slave首次同步数据：当master结点收到slave结点来的syn同步请求，会生成一个新的进程，将内存数据dump到文件上，然后再同步到slave结点中； </li>    <li>AOF日志重写：使用AOF持久化方式，做AOF文件重写操作会创建新的进程做重写；（重写并不会去读已有的文件，而是直接使用内存中的数据写成归档日志）； </li> </ul>

<p><strong>解决方案：</strong>     <br />为了应对大内存页表复制时带来的影响，有些可用的措施：</p>

<ol>   <li>     <p>控制每个redis实例的最大内存量；        <br />不让fork带来的限制太多，可以从内存量上控制fork的时延；         <br />一般建议不超过20G，可根据自己服务器的性能来确定（内存越大，持久化的时间越长，复制页表的时间越长，对事件循环的阻塞就延长）         <br />新浪微博给的建议是不超过20G，而我们虚机上的测试，要想保证应用毛刺不明显，可能得在10G以下；</p>   </li>    <li>     <p>使用大内存页，默认内存页使用4KB，这样，当使用40G的内存时，页表就有80M；而将每个内存页扩大到4M，页表就只有80K；这样复制页表几乎没有阻塞，同时也会提高快速页表缓冲TLB（translation lookaside buffer）的命中率；但大内存页也有问题，在写时复制时，只要一个页快中任何一个元素被修改，这个页块都需要复制一份（COW机制的粒度是页面），这样在写时复制期间，会耗用更多的内存空间；</p>   </li>    <li>     <p>使用物理机；        <br />如果有的选，物理机当然是最佳方案，比上面都要省事;         <br />当然，虚拟化实现也有多种，除了Xen系统外，现代的硬件大部分都可以快速的复制页表；         <br />但公司的虚拟化一般是成套上线的，不会因为我们个别服务器的原因而变更，如果面对的只有Xen，只能想想如何用好它；</p>   </li>    <li>     <p>杜绝新进程的产生，不使用持久化，不在主结点上提供查询；实现起来有以下方案：        <br /><strong>1）</strong> 只用单机，不开持久化，不挂slave结点。这样最简单，不会有新进程的产生；但这样的方案只适合缓存；         <br />如何来做这个方案的高可用？         <br />要做高可用，可以在写redis的前端挂上一个消息队列，在消息队列中使用pub-sub来做分发，保证每个写操作至少落到2个结点上；因为所有结点的数据相同，只需要用一个结点做持久化，这个结点对外不提供查询；         <br />        <br /><a href="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/image3.png"><img style="border-right-width: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; margin-left: 0px; border-left-width: 0px; margin-right: 0px" title="image" border="0" alt="image" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/image_thumb.png" width="548" height="310" /></a>         <br />        <br /><strong>2）</strong> master-slave：在主结点上开持久化，主结点不对外提供查询，查询由slave结点提供，从结点不提供持久化；这样，所有的fork耗时的操作都在主结点上，而查询请求由slave结点提供；         <br />这个方案的问题是主结点坏了之后如何处理？         <br />简单的实现方案是主不具有可替代性，坏了之后，redis集群对外就只能提供读，而无法更新；待主结点启动后，再继续更新操作；对于之前的更新操作，可以用MQ缓存起来，等主结点起来之后消化掉故障期间的写请求；         <br />        <br /><img style="border-right-width: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px" title="image" border="0" alt="image" src="http://blogcc.u.qiniudn.com/wp-content/uploads/2015/12/image4.png" width="616" height="318" />         <br />        <br />如果使用官方的Sentinel将从升级为主，整体实现就相对复杂了；需要更改可用从的ip配置，将其从可查询结点中剔除，让前端的查询负载不再落在新主上；然后，才能放开sentinel的切换操作，这个前后关系需要保证；</p>   </li> </ol>

<h2 id="-">持久化造成的阻塞</h2>

<p>执行持久化（AOF / RDB snapshot)对系统性能有较大影响，特别是服务器结点上还有其它读写磁盘的操作时（比如，应用服务和redis服务部署在相同结点上，应用服务实时记录进出报日志）；应尽可能避免在IO已经繁重的结点上开Redis持久化；</p>

<h3 id="-write-fsync-">子进程持久化时，子进程的write和主进程的fsync冲突造成阻塞</h3>

<p>在开启了AOF持久化的结点上，当子进程执行AOF重写或者RDB持久化时，出现了Redis查询卡顿甚至长时间阻塞的问题, 此时, Redis无法提供任何读写操作；</p>

<p>原因分析：    <br />Redis 服务设置了 appendfsync everysec, 主进程每秒钟便会调用 fsync(), 要求内核将数据”确实”写到存储硬件里. 但由于服务器正在进行大量IO操作, 导致主进程 fsync()/操作被阻塞, 最终导致 Redis 主进程阻塞.</p>

<p>redis.conf中是这么说的：    <br />When the AOF fsync policy is set to always or everysec, and a background     <br />saving process (a background save or AOF log background rewriting) is     <br />performing a lot of I/O against the disk, in some Linux configurations     <br />Redis may block too long on the fsync() call. Note that there is no fix for     <br />this currently, as even performing fsync in a different thread will block     <br />our synchronous write(2) call.     <br />当执行AOF重写时会有大量IO，这在某些Linux配置下会造成主进程fsync阻塞；</p>

<p><strong>解决方案：</strong>     <br />设置 no-appendfsync-on-rewrite yes, 在子进程执行AOF重写时, 主进程不调用fsync()操作；注意, 即使进程不调用 fsync(), 系统内核也会根据自己的算法在适当的时机将数据写到硬盘(Linux 默认最长不超过 30 秒).     <br />这个设置带来的问题是当出现故障时，最长可能丢失超过30秒的数据，而不再是1秒；</p>

<h3 id="-aof-sync-write-">子进程AOF重写时，系统的sync造成主进程的write阻塞</h3>

<p>我们来梳理下：    <br />1) 起因：有大量IO操作write(2) 但未主动调用同步操作     <br />2) 造成kernel buffer中有大量脏数据     <br />3) 系统同步时，sync的同步时间过长     <br />4) 造成redis的写aof日志write(2)操作阻塞；     <br />5) 造成单线程的redis的下一个事件无法处理，整个redis阻塞（redis的事件处理是在一个线程中进行，其中写aof日志的write(2)是同步阻塞模式调用，与网络的非阻塞write(2)要区分开来）</p>

<p>产生1)的原因：这是redis2.6.12之前的问题，AOF rewrite时一直埋头的调用write(2)，由系统自己去触发sync。    <br />另外的原因：系统IO繁忙，比如有别的应用在写盘；</p>

<p><strong>解决方案：</strong>     <br />控制系统sync调用的时间；需要同步的数据多时，耗时就长；缩小这个耗时，控制每次同步的数据量；通过配置按比例(vm.dirty_background_ratio)或按值(vm.dirty_bytes)设置sync的调用阈值；（一般设置为32M同步一次）     <br />2.6.12以后，AOF rewrite 32M时会主动调用fdatasync；</p>

<p>另外，Redis当发现当前正在写的文件有在执行fdatasync(2)时，就先不调用write(2)，只存在cache里，免得被block。但如果已经超过两秒都还是这个样子，则会强行执行write(2)，即使redis会被block住。</p>

<h3 id="aof-">AOF重写完成后合并数据时造成的阻塞</h3>

<p>在bgrewriteaof过程中，所有新来的写入请求依然会被写入旧的AOF文件，同时放到AOF buffer中，当rewrite完成后，会在主线程把这部分内容合并到临时文件中之后才rename成新的AOF文件，所以rewrite过程中会不断打印&quot;Background AOF buffer size: 80 MB， Background AOF buffer size: 180 MB&quot;，要监控这部分的日志。这个合并的过程是阻塞的，如果产生了280MB的buffer，在100MB/s的传统硬盘上，Redis就要阻塞2.8秒；</p>

<p><strong>解决方案：</strong>     <br />将硬盘设置的足够大，将AOF重写的阈值调高，保证高峰期间不会触发重写操作；在闲时使用crontab 调用AOF重写命令；</p>

<p>参考：    <br /><a href="http://www.oschina.net/translate/redis-latency-problems-troubleshooting">http://www.oschina.net/translate/redis-latency-problems-troubleshooting</a>     <br /><a href="https://github.com/springside/springside4/wiki/redis">https://github.com/springside/springside4/wiki/redis</a></p>

<p>Posted by: 大CC | 09DEC,2015    <br />博客：<a href="http://blog.me115.com">blog.me115.com</a> [<a href="http://blog.me115.com/feed">订阅</a>]     <br />Github：<a href="https://github.com/me115">大CC</a></p>

<div class="ujian-hook"></div><div style='clear:both;'></div>

 
		<script type="text/javascript">
		var ujian_config = {
			'num':5,
			'showType':2,
			'bgColor':"",
			'mouseoverColor':"#E6F3DE",
			'textColor':"#333333",
			'hoverTextColor':"#333333",
			'borderColor':"#dddddd",
			'picSize':96,
			'target':1,
			'textHeight':60,
			'defaultPic':"",
			'itemTitle':"您可能喜欢："
		}</script>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>]]></content:encoded>
			<wfw:commentRss>http://blog.me115.com/2015/12/891/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>负载均衡的几种常用方案</title>
		<link>http://blog.me115.com/2015/11/886</link>
		<comments>http://blog.me115.com/2015/11/886#comments</comments>
		<pubDate>Fri, 27 Nov 2015 05:55:27 +0000</pubDate>
		<dc:creator>大CC</dc:creator>
				<category><![CDATA[架构]]></category>
		<category><![CDATA[负载均衡]]></category>

		<guid isPermaLink="false">http://blog.me115.com/?p=886</guid>
		<description><![CDATA[负载均衡的几种常用方案 总结下负载均衡的常用方案及适用场景； Round Rob &#8230;<p class="read-more"><a href="http://blog.me115.com/2015/11/886">继续阅读 &#187;</a></p>]]></description>
				<content:encoded><![CDATA[<h1 id="-">负载均衡的几种常用方案</h1>

<p>总结下负载均衡的常用方案及适用场景；</p>

<h2 id="round-robin-">Round Robin 轮询调度</h2>

<p>以轮询的方式依次请求调度不同的服务器；   <br />实现时，一般为服务器带上权重；这样有两个好处：</p>

<ol>   <li>针对服务器的性能差异可分配不同的负载； </li>    <li>当需要将某个结点剔除时，只需要将其权重设置为0即可； </li> </ol>

<p>优点：实现简单、高效；易水平扩展；   <br />缺点：请求到目的结点的不确定，造成其无法适用于有写的场景（缓存，数据库写）    <br />应用场景：数据库或应用服务层中只有读的场景；</p>

<h2 id="-">随机方式</h2>

<p>请求随机分布到各个结点；在数据足够大的场景能达到一个均衡分布；   <br />优点：实现简单、易水平扩展；    <br />缺点：同Round Robin，无法用于有写的场景；    <br />应用场景：数据库负载均衡，也是只有读的场景；</p>

<h2 id="-">哈希方式</h2>

<p>根据key来计算需要落在的结点上，可以保证一个同一个键一定落在相同的服务器上；   <br />优点：相同key一定落在同一个结点上，这样就可用于有写有读的缓存场景；    <br />缺点：在某个结点故障后，会导致哈希键重新分布，造成命中率大幅度下降；    <br />解决：一致性哈希 or 使用keepalived保证任何一个结点的高可用性，故障后会有其它结点顶上来；    <br />应用场景：缓存，有读有写；</p>

<h2 id="-">一致性哈希</h2>

<p>在服务器一个结点出现故障时，受影响的只有这个结点上的key，最大程度的保证命中率；   <br />如twemproxy中的ketama方案；    <br />生产实现中还可以规划指定子key哈希，从而保证局部相似特征的键能分布在同一个服务器上；    <br />优点：结点故障后命中率下降有限；    <br />应用场景：缓存；</p>

<h2 id="-">根据键的范围来负载</h2>

<p>根据键的范围来负载，前1亿个键都存放到第一个服务器，1~2亿在第二个结点；   <br />优点：水平扩展容易，存储不够用时，加服务器存放后续新增数据；    <br />缺点：负载不均；数据库的分布不均衡；（数据有冷热区分，一般最近注册的用户更加活跃，这样造成后续的服务器非常繁忙，而前期的结点空闲很多）    <br />适用场景：数据库分片负载均衡；</p>

<h2 id="-">根据键对服务器结点数取模来负载；</h2>

<p>根据键对服务器结点数取模来负载；比如有4台服务器，key取模为0的落在第一个结点，1落在第二个结点上。   <br />优点：数据冷热分布均衡，数据库结点负载均衡分布；    <br />缺点：水平扩展较难；    <br />适用场景：数据库分片负载均衡；</p>

<h2 id="-">纯动态结点负载均衡</h2>

<p>根据CPU、IO、网络的处理能力来决策接下来的请求如何调度；   <br />优点：充分利用服务器的资源，保证个结点上负载处理均衡；    <br />缺点：实现起来复杂，真实使用较少；</p>

<h2 id="-">不用主动负载均衡；</h2>

<p>使用消息队列转为异步模型，将负载均衡的问题消灭   <br />负载均衡是一种推模型，一直向你发数据，那么，将所有的用户请求发到消息队列中，所有的下游结点谁空闲，谁上来取数据处理；转为拉模型之后，消息了负载的问题；    <br />优点：通过消息队列的缓冲，保护后端系统，请求剧增时不会冲垮后端服务器；    <br />水平扩展容易，加入新结点后，直接取queue即可；    <br />缺点：不具有实时性；    <br />应用场景：不需要实时返回的场景；    <br />比如，12036下订单后，立刻返回提示信息：您的订单进去排队了&#8230;等处理完毕后，再异步通知；</p>

<h2 id="-">相关开源工具</h2>

<ul>   <li>     <p>HAProxy：可用来做redis多个结点的负载均衡、也可做mysql等数据库的负载、支持4层负载和7层负载；（一般配合Keepalived做高可用）</p>   </li>    <li>     <p>Twemproxy：用来做redis的结点的分片、redis的存储受限与单个结点的内存容量，数据量大到需要分片，使用twemproxy可做到对业务层透明的分片；       <br />twemproxy也是使用的单线程reactor模型，一个twemproxy后端接再多的redis结点，其能够支撑的TPS不会超过单个redis结点的处理能力，使用时需要启动多个twemproxy对外提供查询结点；</p>   </li>    <li>     <p>nginx：目前的明星开源产品，只支持7层负载，除了用于反向代理负载均衡，更出名的是作为WEB服务器；</p>   </li>    <li>LVS：使用Linux内核集群实现一个高性能、高可用的负载均衡服务器，采用IP负载均衡技术和基于内容请求分发技术。未用过这个，有兴趣的同学可看看这篇文章：<a href="http://www.ha97.com/5646.html；">http://www.ha97.com/5646.html；</a> </li> </ul>

<p>Posted by: 大CC | 27NOV,2015   <br />博客：<a href="http://blog.me115.com">blog.me115.com</a> [<a href="http://blog.me115.com/feed">订阅</a>]    <br />Github：<a href="https://github.com/me115">大CC</a></p>

<div class="ujian-hook"></div><div style='clear:both;'></div>

 
		<script type="text/javascript">
		var ujian_config = {
			'num':5,
			'showType':2,
			'bgColor':"",
			'mouseoverColor':"#E6F3DE",
			'textColor':"#333333",
			'hoverTextColor':"#333333",
			'borderColor':"#dddddd",
			'picSize':96,
			'target':1,
			'textHeight':60,
			'defaultPic':"",
			'itemTitle':"您可能喜欢："
		}</script>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>]]></content:encoded>
			<wfw:commentRss>http://blog.me115.com/2015/11/886/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Redis哈希表的实现要点</title>
		<link>http://blog.me115.com/2015/11/884</link>
		<comments>http://blog.me115.com/2015/11/884#comments</comments>
		<pubDate>Fri, 20 Nov 2015 08:16:50 +0000</pubDate>
		<dc:creator>大CC</dc:creator>
				<category><![CDATA[Redis]]></category>
		<category><![CDATA[redis]]></category>

		<guid isPermaLink="false">http://blog.me115.com/?p=884</guid>
		<description><![CDATA[Redis哈希表的实现要点 哈希算法的选择 针对不同的key使用不同的hash算 &#8230;<p class="read-more"><a href="http://blog.me115.com/2015/11/884">继续阅读 &#187;</a></p>]]></description>
				<content:encoded><![CDATA[<h1 id="redis-">Redis哈希表的实现要点</h1>

<h2 id="-">哈希算法的选择</h2>

<p>针对不同的key使用不同的hash算法，如对整型、字符串以及大小写敏感的字符串分别使用不同的hash算法；</p>

<p>整型的Hash算法使用的是Thomas Wang&#8217;s 32 Bit / 64 Bit Mix Function ，这是一种基于位移运算的散列方法。基于移位的散列是使用Key值进行移位操作。通常是结合左移和右移。每个移位过程的结果进行累加，最后移位的结果作为最终结果。这种方法的好处是避免了乘法运算，从而提高Hash函数本身的性能。</p>

<pre><code>unsigned int dictIntHashFunction(unsigned int key)
{
    key += ~(key &lt;&lt; 15);
    key ^=  (key &gt;&gt; 10);
    key +=  (key &lt;&lt; 3);
    key ^=  (key &gt;&gt; 6);
    key += ~(key &lt;&lt; 11);
    key ^=  (key &gt;&gt; 16);
    return key;
}</code></pre>

<p>字符串使用的MurmurHash算法，MurmurHash算法具有高运算性能，低碰撞率的特点，由Austin Appleby创建于2008年，现已应用到Hadoop、libstdc++、nginx、libmemcached等开源系统。2011年Appleby被Google雇佣，随后Google推出其变种的CityHash算法。 
  <br />murmur是 multiply and rotate的意思，因为算法的核心就是不断的乘和移位（x *= m; k ^= k &gt;&gt; r;）</p>

<pre><code>unsigned int dictGenHashFunction(const void *key, int len) {
    /* 'm' and 'r' are mixing constants generated offline.
     They're not really 'magic', they just happen to work well.  */
    uint32_t seed = dict_hash_function_seed;
    const uint32_t m = 0x5bd1e995;
    const int r = 24;

    /* Initialize the hash to a 'random' value */
    uint32_t h = seed ^ len;

    /* Mix 4 bytes at a time into the hash */
    const unsigned char *data = (const unsigned char *)key;

    while(len &gt;= 4) {
        uint32_t k = *(uint32_t*)data;

        k *= m;
        k ^= k &gt;&gt; r;
        k *= m;

        h *= m;
        h ^= k;

        data += 4;
        len -= 4;
    }

    /* Handle the last few bytes of the input array  */
    switch(len) {
    case 3: h ^= data[2] &lt;&lt; 16;
    case 2: h ^= data[1] &lt;&lt; 8;
    case 1: h ^= data[0]; h *= m;
    };

    /* Do a few final mixes of the hash to ensure the last few
     * bytes are well-incorporated. */
    h ^= h &gt;&gt; 13;
    h *= m;
    h ^= h &gt;&gt; 15;

    return (unsigned int)h;
}</code></pre>

<p>一个好的hash算法需要满足两个条件： 
  <br />1) 性能高，运算足够快； 

  <br />2) 相邻的数据hash后分布广；即使输入的键是有规律的，算法仍然能给出一个很好的随机分布性； 

  <br />比如：murmur计算&quot;abc&quot;是1118836419，&quot;abd&quot;是413429783。而使用Horner算法，&quot;abc&quot;是96354， &quot;abd&quot;就比它多1（96355）；</p>

<h2 id="rehash">rehash</h2>

<p>负载因子 = 当前结点数/桶的大小，超过1表示肯定有碰撞了；碰撞的结点，通过链表拉链起来；</p>

<p>所有哈希表的初始桶的大小为4，根据负载因子的变化进行rehash，重新分配空间（扩展或收缩）</p>

<p>当hash表的负载因子超过1后，进行扩展（小于0.01时，进行收缩）； 
  <br />所谓扩展，就是新建一个hash表2，将桶的数量增大（具体增大为：第一个大于等于usedSize的2的n次冥）；然后将hash表1中结点都转移到hash表2中；</p>

<p>rehash的触发条件： 
  <br />当做BGSAVE或BGREWRITEEOF时，负载因子超过5时触发rehash， 

  <br />没有BGSAVE或BGREWRITEEOF时，负载因子超过1时触发rehash；</p>

<p>在BGSAVE或BGREWRITEEOF时，使用到Linux的写时复制，如果这时候做rehash，将会好用更多的内存空间（没有变化的结点用一份，变化的结点复制一份）</p>

<h2 id="-rehash">渐进式rehash</h2>

<p>一个hash表中的数据可能有几百上千万，不可能一次rehash转移完，需要分批逐渐转移； 
  <br />在rehash的过程中，对redis的查询、更新操作首先会在hash0中查找，没有找到，然后转到hash1中操作； 

  <br />对于插入操作，直接插入到hash1中；最终目标是将hash表1变为空表，rehash完成；</p>

<h2 id="value-">value的存储</h2>

<p>键值对的实现，value 是一个union，对整型和字符串使用不同的存储对象；</p>

<pre><code>// 键
void *key;

// 值
union {
    void *val;
    uint64_t u64;
    int64_t s64;
} v;</code></pre>

<p>ref： 
  <br />《Hash 函数概览》<a href="http://www.oschina.net/translate/state-of-hash-functions">http://www.oschina.net/translate/state-of-hash-functions</a> 

  <br />《redis设计与实现》</p>

<p>Posted by: 大CC | 18NOV,2015 
  <br />博客：<a href="http://blog.me115.com">blog.me115.com</a> [<a href="http://blog.me115.com/feed">订阅</a>] 

  <br />Github：<a href="https://github.com/me115">大CC</a></p>

<div class="ujian-hook"></div><div style='clear:both;'></div>

 
		<script type="text/javascript">
		var ujian_config = {
			'num':5,
			'showType':2,
			'bgColor':"",
			'mouseoverColor':"#E6F3DE",
			'textColor':"#333333",
			'hoverTextColor':"#333333",
			'borderColor':"#dddddd",
			'picSize':96,
			'target':1,
			'textHeight':60,
			'defaultPic':"",
			'itemTitle':"您可能喜欢："
		}</script>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>]]></content:encoded>
			<wfw:commentRss>http://blog.me115.com/2015/11/884/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>多线程和多进程模型的选用</title>
		<link>http://blog.me115.com/2015/10/875</link>
		<comments>http://blog.me115.com/2015/10/875#comments</comments>
		<pubDate>Sat, 10 Oct 2015 02:38:44 +0000</pubDate>
		<dc:creator>大CC</dc:creator>
				<category><![CDATA[Linux&Unix]]></category>
		<category><![CDATA[多线程]]></category>

		<guid isPermaLink="false">http://blog.me115.com/?p=875</guid>
		<description><![CDATA[多线程和多进程模型的选用 这里的线程指通过linux的pthread_creat &#8230;<p class="read-more"><a href="http://blog.me115.com/2015/10/875">继续阅读 &#187;</a></p>]]></description>
				<content:encoded><![CDATA[<h1 id="-">多线程和多进程模型的选用</h1>

<p>这里的线程指通过linux的pthread_create而产生的原生线程，线程资源很宝贵，能被操作系统的任务调度器看见的（不是python gevent、go gorouine里的概念）；   <br />我们讨论以下两种模型；</p>

<ol>   <li>多进程单线程模型（以下简称为多进程）； </li>    <li>单进程多线程模型（以下简称为多线程）； </li> </ol>

<h2 id="-">多进程模型</h2>

<h3 id="-">优点</h3>

<p>编程相对容易；通常不需要考虑锁和同步资源的问题。   <br />更强的容错性:比起多线程的一个好处是一个进程崩溃了不会影响其他进程。    <br />有内核保证的隔离：数据和错误隔离。    <br />对于使用如C/C++这些语言编写的本地代码，错误隔离是非常有用的：采用多进程架构的程序一般可以做到一定程度的自恢复；（master守护进程监控所有worker进程，发现进程挂掉后将其重启）</p>

<h3 id="-">多进程的案例</h3>

<p>nginx主流的工作模式是多进程模式（也支持多线程模型）   <br />几乎所有的web server服务器服务都有多进程的，至少有一个守护进程配合一个worker进程，例如apached,httpd等等以d结尾的进程包括init.d本身就是0级总进程，所有你认知的进程都是它的子进程；    <br />chrome浏览器也是多进程方式。    <br />redis也可以归类到“多进程单线程”模型（平时工作是单个进程，涉及到耗时操作如持久化或aof重写时会用到多个进程）</p>

<h2 id="-">多线程模型</h2>

<h3 id="-">优点</h3>

<p>多线程优点：创建速度快，方便高效的数据共享   <br />共享数据：多线程间可以共享同一虚拟地址空间；多进程间的数据共享就需要用到共享内存、信号量等IPC技术；</p>

<p>较轻的上下文切换开销 &#8211; 不用切换地址空间，不用更改寄存器，不用刷新TLB。   <br />提供非均质的服务    <br />如果全都是计算任务，但每个任务的耗时不都为1s，而是1ms-1s之间波动；这样，多线程相比多进程的优势就体现出来，它能有效降低“简单任务被复杂任务压住”的概率；</p>

<h3 id="-">适用的场景</h3>

<p>1 线程间有数据共享，并且数据是需要修改的（不同任务间需要大量共享数据或频繁通信时）；   <br />2 提供非均质的服务（有优先级任务处理）事件响应有优先级；    <br />3 单任务并行计算，在非CPU Bound的场景下提高响应速度，降低时延；    <br />4 与人有IO交互的应用，良好的用户体验（键盘鼠标的输入，立刻响应）</p>

<h3 id="-">多线程案例</h3>

<p>桌面软件，响应用户输入的是一个线程，后台程序处理是另外的线程；   <br />memcached</p>

<h2 id="-">选用</h2>

<p>单进程多线程和多进程单线程，2种模式如何取舍？   <br />进程线程间创建的开销不足作为选择的依据，因为一般我们都是使用线程池或者进程池，在系统启动时就创建了固定的线程或进程，不会频繁的创建和销毁；</p>

<p>首先，根据工作集（需要共享的内存）的大小来定；如果工作集较大，就用多线程，避免cpu cache频繁的换入换出；比如memcached缓存系统；</p>

<p>其次，选择的依据根据以上多线程适用的场景来对比自身的业务场景，是否有这样场景需求：数据共享、提供非均质的服务，单任务拆散并行化等；   <br />如果没有必要，或者多进程就可以很好的胜任，就多用多进程，享受单线程编程带来便利；</p>

<p>RCU的发明者，Paul McKenny 在《Is Parallel Programming Hard, And, If So, What Can You Do About It?》说过：   <br />能用多进程方便的解决问题的时候不要使用多线程。</p>

<h2 id="-">参考</h2>

<p>ref：《Linux多线程服务端编程：使用muduo网络库》   <br />ref：<a href="http://www.zhihu.com/question/19903801">http://www.zhihu.com/question/19903801</a>    <br />ref：<a href="https://computing.llnl.gov/tutorials/pthreads/#WhyPthreads">https://computing.llnl.gov/tutorials/pthreads/#WhyPthreads</a></p>

<p>&#160;</p>

<p>Posted by: 大CC | 10OCT,2015   <br />博客：<a href="http://blog.me115.com">blog.me115.com</a> [<a href="http://blog.me115.com/feed">订阅</a>]    <br />Github：<a href="https://github.com/me115">大CC</a></p>

<div class="ujian-hook"></div><div style='clear:both;'></div>

 
		<script type="text/javascript">
		var ujian_config = {
			'num':5,
			'showType':2,
			'bgColor':"",
			'mouseoverColor':"#E6F3DE",
			'textColor':"#333333",
			'hoverTextColor':"#333333",
			'borderColor':"#dddddd",
			'picSize':96,
			'target':1,
			'textHeight':60,
			'defaultPic':"",
			'itemTitle':"您可能喜欢："
		}</script>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>]]></content:encoded>
			<wfw:commentRss>http://blog.me115.com/2015/10/875/feed</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>异步和非阻塞</title>
		<link>http://blog.me115.com/2015/10/872</link>
		<comments>http://blog.me115.com/2015/10/872#comments</comments>
		<pubDate>Fri, 09 Oct 2015 01:12:15 +0000</pubDate>
		<dc:creator>大CC</dc:creator>
				<category><![CDATA[Linux&Unix]]></category>

		<guid isPermaLink="false">http://blog.me115.com/?p=872</guid>
		<description><![CDATA[异步和非阻塞 今天看了篇知乎讨论，将异步和非阻塞讲的透彻；在这里整理出来； 同步 &#8230;<p class="read-more"><a href="http://blog.me115.com/2015/10/872">继续阅读 &#187;</a></p>]]></description>
				<content:encoded><![CDATA[<h1 id="-">异步和非阻塞</h1>

<p>今天看了篇知乎讨论，将异步和非阻塞讲的透彻；在这里整理出来；</p>

<h2 id="-">同步异步</h2>

<p>同步和异步关注的是 <strong>消息通信机制</strong>    <br />同步，就是在发出一个 <strong>调用</strong> 时，在没有得到结果之前，该<strong>调用</strong>就不返回。但是一旦调用返回，就得到返回值了。    <br />换句话说，就是由<strong>调用者</strong>主动等待这个<strong>调用</strong>的结果。</p>

<p>异步则相反，<strong>调用</strong>在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在<strong>调用</strong>发出后，<strong>被调用者</strong>通过状态、通知来通知调用者，或通过回调函数处理这个调用。</p>

<h2 id="-">阻塞与非阻塞</h2>

<p>阻塞和非阻塞关注的是 <strong>程序在等待调用结果（消息，返回值）时的状态</strong>.    <br />阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。    <br />非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。当然，这就不知道调用是否完成，一般通过轮询定期来探查调用是否完成；</p>

<h2 id="io-">IO层面的同步异步</h2>

<p>在处理IO的时候，阻塞和非阻塞都是同步；如：IO多路复用（select/poll/epoll);   <br />只有使用了特殊API，才是异步IO，如：linux的AIO、Windows的IOCP .NET的beginInvoke/EndInvoke;    <br /></p>

<h2 id="-">通俗的例子</h2>

<h3 id="-">买书</h3>

<p>你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下&quot;，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。   <br />而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。</p>

<p>你打电话问书店老板有没有《分布式系统》这本书，你如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果，如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了， 当然你也要偶尔过几分钟check一下老板有没有返回结果。   <br />在这里阻塞与非阻塞与是否同步异步无关。跟老板通过什么方式回答你结果无关。</p>

<h3 id="-">喝茶</h3>

<p>另一个有趣的例子：   <br />老张爱喝茶，废话不说，煮开水。    <br />出场人物：老张，水壶两把（普通水壶，简称水壶；会响的水壶，简称响水壶）。    <br />1 老张把水壶放到火上，立等水开。（同步阻塞）    <br />老张觉得自己有点傻    <br />2 老张把水壶放到火上，去客厅看电视，时不时去厨房看看水开没有。（同步非阻塞）    <br />老张还是觉得自己有点傻，于是变高端了，买了把会响笛的那种水壶。水开之后，能大声发出嘀~~~~的噪音。    <br />3 老张把响水壶放到火上，立等水开。（异步阻塞）    <br />老张觉得这样傻等意义不大    <br />4 老张把响水壶放到火上，去客厅看电视，水壶响之前不再去看它了，响了再去拿壶。（异步非阻塞）    <br />老张觉得自己聪明了。</p>

<p>所谓同步异步，只是对于水壶而言。   <br />普通水壶，同步；响水壶，异步。    <br />虽然都能干活，但响水壶可以在自己完工之后，提示老张水开了。这是普通水壶所不能及的。    <br />同步只能让调用者去轮询自己（情况2中），造成老张效率的低下。</p>

<p>所谓阻塞非阻塞，仅仅对于老张而言。   <br />立等的老张，阻塞；看电视的老张，非阻塞。    <br />情况1和情况3中老张就是阻塞的，媳妇喊他都不知道。虽然3中响水壶是异步的，可对于立等的老张没有太大的意义。所以一般异步是配合非阻塞使用的，这样才能发挥异步的效用。</p>

<p>整理自：<a href="http://www.zhihu.com/question/19732473">http://www.zhihu.com/question/19732473</a></p>

<div class="ujian-hook"></div><div style='clear:both;'></div>

 
		<script type="text/javascript">
		var ujian_config = {
			'num':5,
			'showType':2,
			'bgColor':"",
			'mouseoverColor':"#E6F3DE",
			'textColor':"#333333",
			'hoverTextColor':"#333333",
			'borderColor':"#dddddd",
			'picSize':96,
			'target':1,
			'textHeight':60,
			'defaultPic':"",
			'itemTitle':"您可能喜欢："
		}</script>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>]]></content:encoded>
			<wfw:commentRss>http://blog.me115.com/2015/10/872/feed</wfw:commentRss>
		<slash:comments>1</slash:comments>
		</item>
	</channel>
</rss>

<!-- Dynamic page generated in 0.188 seconds. -->
<!-- Cached page generated by WP-Super-Cache on 2016-07-03 08:06:28 -->
